{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file dimension :  (35249, 3)\n",
      "#Unique Intents :  570\n",
      "Unique Intents after preprocessing : 455\n",
      "\n",
      "Running preprocessing ...\n",
      "Preprocessing completed successfully\n",
      "\n",
      "Running featurizer ...\n",
      "Saving TF-IDF vectors to ../temp/tfidf_pre_trained_vectors.pkl\n",
      "Featurization process completed successfully\n",
      "(33860, 68124)\n",
      "\n",
      "Training data feature dimension: (33860, 68124)\n",
      "Training labels dimension: (33860, 1)\n",
      "\n",
      "Training Logistic Regression Model for 455 Intents\n",
      "Saving trained logistic_regression model  to ../temp/logistic_regression_model.pkl\n",
      "\n",
      "Training Process Completed Successfully\n"
     ]
    }
   ],
   "source": [
    "#training step\n",
    "!python train.py --data_dir ../data/ \\\n",
    "                 --train_file SEC_Export_Final.csv \\      #file name with extension. \n",
    "                 --model_dir ../models/ \\   #export model artifcats path\n",
    "                 --use_social no \\    # just social flags\n",
    "                 --spacy_features no  #spacy features  yes /no flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file dimension :  (27958, 8)\n",
      "\n",
      "Running preprocessing ...\n",
      "Preprocessing completed successfully\n",
      "\n",
      "Running featurizer ...\n",
      "Featurization process completed successfully\n",
      "(27958, 59376)\n",
      "Test data feature dimension: (27958, 59376)\n",
      "\n",
      "Running Model Predictions ..\n",
      "Model predictions Done\n"
     ]
    }
   ],
   "source": [
    "# evaluation mode when truth labels are provided in test data. \n",
    "!python validate.py --data_dir ../data/ \\\n",
    "                 --test_file f2.csv \\\n",
    "                 --model_dir ../models/ \\\n",
    "                 --use_social no \\\n",
    "                 --spacy_features yes \\\n",
    "                 --tag unlabelled   ## uncomment this for batch inference, when truth labels bot are provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "##t1=t.sample(frac=0.5,replace=False,random_state=100)\n",
    "#print(t1.shape)\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "brackets_re = re.compile(r\"[(\\[].*?[)\\]]\")\n",
    "replace_by_space_re = re.compile(r\"[{}|@,;]\")\n",
    "non_alphanum_re = re.compile(r\"[^0-9a-z#+_]\")\n",
    "\n",
    "def clean_text(text, spell_check=False):\n",
    "    text = str(text).lower()  # lowercase text\n",
    "    # regex clean operations\n",
    "    text = re.sub(brackets_re, \"\", text)  # remove [] & () brackets\n",
    "    text = re.sub(replace_by_space_re, \" \", text)  # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = re.sub(non_alphanum_re, \" \", text)  # delete symbols which are not alphanumeric numbers from text\n",
    "    #text=re.sub(re.sub(re.sub(re.sub(re.sub(re.sub(\"%20\", \" \",text), \"%7c\",text), \"|\",text), \"%2f\",text), \"/\",text), \"%3a\", \"\")\n",
    "    text=str(text).replace(\"redacted\",\"\")\n",
    "    #text=str(text).replace('xe2 x80 x99t',\"\")\n",
    "    text=str(text).replace('xe2',\"\")\n",
    "    text=str(text).replace('x80',\"\")\n",
    "    text=str(text).replace('x99t',\"\")\n",
    "    #text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    # in-house financial spell checker\n",
    "    if spell_check:\n",
    "        text = \" \".join(sc.correction(sc.tokenize(text)))\n",
    "    #lemmatization\n",
    "    text = \" \".join([lemmatizer.lemmatize(w) for w in text.split(\" \")])\n",
    "    #text=\" \".join([word for word in text.split(\" \") if word not in stopwords.words('english')])\n",
    "    return text\n",
    "# t1['sent']=t1.message_text.apply(clean_text)\n",
    "# t1=t1[['sent']]\n",
    "# print(t1.shape)\n",
    "#t1.to_csv(\"../data/clean_set.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd,os,sys,numpy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ds=pd.read_csv(\"/Users/a656526/Documents/livechats/ds.tsv\",sep=\"\\t\")\n",
    "def clean(text):\n",
    "    text=str(text).lower()\n",
    "    text=re.sub( \"%20\", \" \",text)\n",
    "    text=re.sub( \"%7c\", \" \",text)\n",
    "    text=re.sub( \"%2f\", \" \",text)\n",
    "    text=re.sub( \"%3a\", \" \",text)\n",
    "    text=re.sub( \"%26\", \" \",text)\n",
    "    text=re.sub( \"%2c\", \" \",text)\n",
    "    text=re.sub( \"%3f\", \" \",text)\n",
    "#     text=re.sub( \"/\", \" \",text)\n",
    "#     text=re.sub( \",\", \" \",text)\n",
    "#     text=re.sub( \":\", \" \",text)\n",
    "#     text=re.sub( \"|\", \" \",text)\n",
    "    return text\n",
    "ds['clean_text']=ds._c1.apply(clean)\n",
    "ds['clean_text']=ds.clean_text.apply(clean_text)\n",
    "ds['sent']=ds['clean_text'].str.strip()\n",
    "ds['len']=ds.sent.str.split(\" \").map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525236\n",
      "1269313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ds[ds._c1.notnull()].shape\n",
    "print(ds.clean_text.nunique())\n",
    "print(ds.mid.nunique())\n",
    "#round(ds.len.describe())\n",
    "numpy.percentile(ds.len,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['conv_id', 'message_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "msg=pd.read_csv(\"/Users/a656526/Documents/livechats/msgs_2020.tsv\",sep=\"\\t\",error_bad_lines=False,warn_bad_lines=False)\n",
    "mid=pd.read_csv(\"/Users/a656526/Documents/livechats/mids_2020.tsv\",sep=\"\\t\",error_bad_lines=False,warn_bad_lines=False)\n",
    "print(msg.columns)\n",
    "msg.columns=msg.columns.str.replace(\"nuance_messages_masked.\",\"\")\n",
    "# mid=mid[mid.metrics.notnull()]\n",
    "msg=msg[msg.message_text.notnull()]\n",
    "# #mid=mid[mid.tags.notnull()]\n",
    "\n",
    "mid.drop_duplicates(['conv_id','mid'],inplace=True)\n",
    "# mid['chat_flag']=(mid.metrics.str.contains('Chat'))*1\n",
    "\n",
    "va_mid=msg.merge(mid[['conv_id','mid']],on='conv_id',how='inner')\n",
    "va_mid=va_mid[va_mid.message_text.notnull()]\n",
    "\n",
    "va_mid.shape\n",
    "va_mid['sent']=va_mid.message_text.apply(clean_text)\n",
    "va_mid1['sent']=va_mid1['sent'].str.strip()\n",
    "va_mid['len']=va_mid.sent.str.split(\" \").apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>message_text</th>\n",
       "      <th>mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4476e01e-6991-40a2-a453-ea9489b02c46</td>\n",
       "      <td>loan</td>\n",
       "      <td>ee9c46996645ef11dcbc9e9bc8b53daa77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4476e01e-6991-40a2-a453-ea9489b02c46</td>\n",
       "      <td>can i request a loan online?</td>\n",
       "      <td>ee9c46996645ef11dcbc9e9bc8b53daa77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>e0b0e88a-152c-4c29-bf43-9ac8aa7b9f4a</td>\n",
       "      <td>can i request a loan online?</td>\n",
       "      <td>eee0d5f2e67c0c11d6b90f9bc8b54aaa77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>e467e0bd-4b4a-48f1-ac74-f2767d75ef68</td>\n",
       "      <td>can i rollover my pension to an ira?</td>\n",
       "      <td>eea0f42a5a6e1f11d98d589bc8b54aaa77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>656a3ce5-6f16-4017-a17f-f99cf49f38bb</td>\n",
       "      <td>can i request a loan online?</td>\n",
       "      <td>ee5e7a69690a8820162000e64500d5aa33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 conv_id  \\\n",
       "0   4476e01e-6991-40a2-a453-ea9489b02c46   \n",
       "1   4476e01e-6991-40a2-a453-ea9489b02c46   \n",
       "2   e0b0e88a-152c-4c29-bf43-9ac8aa7b9f4a   \n",
       "3   e467e0bd-4b4a-48f1-ac74-f2767d75ef68   \n",
       "13  656a3ce5-6f16-4017-a17f-f99cf49f38bb   \n",
       "\n",
       "                            message_text                                 mid  \n",
       "0                                   loan  ee9c46996645ef11dcbc9e9bc8b53daa77  \n",
       "1           can i request a loan online?  ee9c46996645ef11dcbc9e9bc8b53daa77  \n",
       "2           can i request a loan online?  eee0d5f2e67c0c11d6b90f9bc8b54aaa77  \n",
       "3   can i rollover my pension to an ira?  eea0f42a5a6e1f11d98d589bc8b54aaa77  \n",
       "13          can i request a loan online?  ee5e7a69690a8820162000e64500d5aa33  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1=ds[ds.mid.isin(va_mid.mid)]\n",
    "va_mid1=va_mid[va_mid.mid.isin(ds.mid.unique())]\n",
    "va_mid1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227324\n",
      "227324\n"
     ]
    }
   ],
   "source": [
    "print(va_mid1.mid.nunique())\n",
    "print(ds1.mid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2590989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1697604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>637271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>227433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>125812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length     freq\n",
       "0       1  2590989\n",
       "1       2  1697604\n",
       "2       3   637271\n",
       "3       4   227433\n",
       "4       5   125812"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1=pd.DataFrame(ds.groupby(['len']).size())\n",
    "i1.reset_index(inplace=True)\n",
    "i1.columns=[ 'length', 'freq']\n",
    "print(i1.shape)\n",
    "i1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     48.0\n",
       "2     31.4\n",
       "3     11.8\n",
       "4      4.2\n",
       "5      2.3\n",
       "6      1.0\n",
       "7      0.5\n",
       "8      0.3\n",
       "9      0.2\n",
       "10     0.1\n",
       "11     0.1\n",
       "12     0.0\n",
       "13     0.0\n",
       "14     0.0\n",
       "15     0.0\n",
       "16     0.0\n",
       "17     0.0\n",
       "18     0.0\n",
       "19     0.0\n",
       "20     0.0\n",
       "21     0.0\n",
       "22     0.0\n",
       "23     0.0\n",
       "24     0.0\n",
       "25     0.0\n",
       "27     0.0\n",
       "30     0.0\n",
       "33     0.0\n",
       "34     0.0\n",
       "38     0.0\n",
       "44     0.0\n",
       "46     0.0\n",
       "47     0.0\n",
       "50     0.0\n",
       "56     0.0\n",
       "57     0.0\n",
       "60     0.0\n",
       "63     0.0\n",
       "69     0.0\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_mid.loc[va_mid.len>28,\"len\"]=28\n",
    "round(ds.len.value_counts(normalize=True)*100,1).sort_index()\n",
    "#round(va_mid.len.value_counts(normalize=True)*100,1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176293, 2)\n",
      "(253, 2)\n"
     ]
    }
   ],
   "source": [
    "i1=pd.DataFrame(ds1.groupby(['sent']).size())\n",
    "i1.reset_index(inplace=True)\n",
    "i1.columns=[ 'sent', 'freq']\n",
    "print(i1.shape)\n",
    "i1=i1[i1.freq>500]\n",
    "i1=i1.sort_values('freq',ascending=False)\n",
    "print(i1.shape)\n",
    "i1.to_csv(\"/Users/a656526/Documents/integration/ds_strings.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>96549</td>\n",
       "      <td>loan</td>\n",
       "      <td>51277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172211</td>\n",
       "      <td>withdraw money</td>\n",
       "      <td>13087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172398</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>12412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96689</td>\n",
       "      <td>loan available</td>\n",
       "      <td>11151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156084</td>\n",
       "      <td>transfer tracker</td>\n",
       "      <td>9550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sent   freq\n",
       "96549               loan  51277\n",
       "172211    withdraw money  13087\n",
       "172398        withdrawal  12412\n",
       "96689     loan available  11151\n",
       "156084  transfer tracker   9550"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320332, 2)\n",
      "(184, 2)\n"
     ]
    }
   ],
   "source": [
    "va_mid1['len']=va_mid1['sent'].str.split(\" \").map(len)\n",
    "va_mid1=va_mid1[va_mid1.len>2]\n",
    "i1=pd.DataFrame(va_mid1.groupby(['sent']).size())\n",
    "i1.reset_index(inplace=True)\n",
    "i1.columns=[ 'sent', 'freq']\n",
    "print(i1.shape)\n",
    "i1=i1[i1.freq>75]\n",
    "i1=i1.sort_values('freq',ascending=False)\n",
    "print(i1.shape)\n",
    "i1.to_csv(\"/Users/a656526/Documents/integration/va_strings.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9238311, 2)\n",
      "(6728344, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd,os,sys,numpy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "t=pd.read_csv(\"../data/msgs_2020.tsv\",sep=\"\\t\")\n",
    "t['message_text']=t['message_text'].astype(str)\n",
    "t=t[t.message_text.notnull()]\n",
    "\n",
    "t['len']=t.message_text.str.split(\" \").apply(len)\n",
    "print(t.shape)\n",
    "t=t[(t.len>2) & (t.len<=15)]\n",
    "#del t['len']\n",
    "#t.reset_index(inplace=True,drop=True)\n",
    "print(t.shape)\n",
    "\n",
    "# t1=t.loc[:round(t.shape[0]/2),:]\n",
    "# t2=t.loc[round(t.shape[0]/2)+1:,:]\n",
    "\n",
    "# t1=t1[t1.message_text.notnull()]\n",
    "# t2=t2[t2.message_text.notnull()]\n",
    "# print(t1.shape)\n",
    "# print(t2.shape)\n",
    "# t1=t1[['message_text']]\n",
    "# t2=t2[['message_text']]\n",
    "# t1.to_csv(\"../data/set1.csv\",index=False)\n",
    "# t2.to_csv(\"../data/set2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running preprocessing ...\n",
      "Preprocessing completed successfully\n",
      "\n",
      "Running featurizer ...\n",
      "Featurization process completed successfully\n",
      "(3300134, 49081)\n",
      "\n",
      "Test data feature dimension: (3300134, 49081)\n",
      "\n",
      "Running Model Predictions ..\n",
      "\n",
      "Model predictions Done\n"
     ]
    }
   ],
   "source": [
    "# evaluation mode when truth labels are provided in test data. \n",
    "!python validate.py --data_dir ../data/ \\\n",
    "                 --test_file clean_set.csv \\\n",
    "                 --model_dir ../temp/ \\\n",
    "                 --use_social no \\\n",
    "                 --spacy_features no \\\n",
    "                 --tag unlabelled   ## uncomment this for batch inference, when truth labels bot are provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd,os,sys,numpy\n",
    "#inp=pd.read_csv(\"../output/predicted_clean_set.csv\")\n",
    "inp=pd.read_csv(\"../data/clean_set.csv\")\n",
    "inp['sent1']=inp.sent.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1826867, 2)\n",
      "(517, 2)\n"
     ]
    }
   ],
   "source": [
    "i1=pd.DataFrame(inp.groupby(['sent1']).size())\n",
    "i1.reset_index(inplace=True)\n",
    "i1.columns=[ 'sent1', 'freq']\n",
    "print(i1.shape)\n",
    "i1=i1[i1.freq>200]\n",
    "i1=i1.sort_values('freq',ascending=False)\n",
    "print(i1.shape)\n",
    "i1.to_csv(\"../output/strings_with_stopwords.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running preprocessing ...\n",
      "Preprocessing completed successfully\n",
      "\n",
      "Running featurizer ...\n",
      "{\n",
      "   \"statusCode\": 400,\n",
      "   \"data\": [\n",
      "      {\n",
      "         \"intent1\": \"\",\n",
      "         \"score1\": 0,\n",
      "         \"tag\": \"\"\n",
      "      },\n",
      "      {\n",
      "         \"intent2\": \"\",\n",
      "         \"score2\": 0,\n",
      "         \"tag\": \"\"\n",
      "      },\n",
      "      {\n",
      "         \"intent3\": \"\",\n",
      "         \"score3\": 0,\n",
      "         \"tag\": \"\"\n",
      "      }\n",
      "   ],\n",
      "   \"message\": \"Error occured in Preprocess/TF-IDF/Inference stage\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from inference import *\n",
    "print(run_inference( '{\"utterance\":\"I want to downlaod my tax form\"}',model_dir=\"../temp/\",spacy_features=\"yes\"))\n",
    "\n",
    "#print(run_inference( '{\"utterance\":\"I want to know my account balance\"}'))\n",
    "\n",
    "#print(run_inference('{}'))\n",
    "\n",
    "#print(run_inference('{\"utterance\":\" withdraw money\"}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pik=\"/Users/a656526/Documents/livechats/data.pkl\"\n",
    "f=open(pik,\"rb\")\n",
    "chat3=pickle.load(f)\n",
    "f.close()\n",
    "chat3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat3=chat3[chat3.msgtext.notnull()]\n",
    "chat3=chat3[chat3.message_text.notnull()]\n",
    "chat3['len1']=chat3.msgtext.str.split(\" \").apply(len)\n",
    "chat3['len2']=chat3.message_text.str.split(\" \").apply(len)\n",
    "chat3=chat3[(chat3.len1>2) & (chat3.len1<20)]\n",
    "chat3=chat3[(chat3.len2>2) & (chat3.len2<20)]\n",
    "chat3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_msg=chat3[['msgtext']]\n",
    "va_msg=chat3[['message_text']]\n",
    "chat_msg.to_csv(\"../../../livechats/chat_msg.csv\",index=False)\n",
    "va_msg.to_csv(\"../../../livechats/va_msg.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python validate.py  --data_dir ../../../livechats/ \\\n",
    "                     --test_file chat_msg.csv \\\n",
    "                     --model_dir ../models/ \\\n",
    "                     --use_social no \\\n",
    "                     --spacy_features no \\\n",
    "                     --tag unlabelled\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "va=pd.read_csv(\"../output/va_msg.csv\")\n",
    "chat=pd.read_csv(\"../output/chat_msg.csv\")\n",
    "chat=chat[chat.display_pred!=\"I want to contact you\"]\n",
    "out=pd.concat([va,chat],axis=1,ignore_index=True)\n",
    "out.columns=[\"va_intent\",\"va_score\",\"chat_intent\",\"chat_score\"]\n",
    "\n",
    "#out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=pd.DataFrame(out.va_intent.value_counts()[:61]).reset_index()\n",
    "list1.columns=['va_intent','freq']\n",
    "list2=pd.DataFrame(out.chat_intent.value_counts()[:61]).reset_index()\n",
    "list2.columns=['chat_intent','freq']\n",
    "out=out[(out.chat_intent.isin(list2.chat_intent)) ]\n",
    "out=out[(out.va_intent.isin(list1.va_intent))]\n",
    "print(out.shape)\n",
    "out.to_csv(\"../output/matrix.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.pivot_table(out,index=\"va_intent\",columns=\"chat_intent\",aggfunc=\"count\")\n",
    "out1=pd.DataFrame(pd.crosstab(index=out['va_intent'], columns=out['chat_intent']))\n",
    "out1.to_csv(\"../output/matrix.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out1.style.background_gradient(cmap='Reds',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "from featurizer import *\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "clean_data=run_preprocess(   data_dir=\"../data/\", \\\n",
    "                                 filename=\"all_data.csv\",\\\n",
    "                                 colnames=['Sentence','Intent','display_column']\n",
    "                                 \n",
    "                         )\n",
    "# call featurizer\n",
    "train_features,y_train=run_featurizer(clean_data,train_eval_predict=\"train\",model_dir=\"../models\")\n",
    "print('\\nTraining data feature dimension: {}'.format(train_features.shape))\n",
    "print('Training labels dimension: {}'.format(y_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,ShuffleSplit\n",
    "\n",
    "#skfold = StratifiedKFold(n_splits=4, random_state=100)\n",
    "skfold=ShuffleSplit(n_splits=5, test_size=0.1, random_state=100)\n",
    "model1=LogisticRegression(random_state=100,n_jobs=-1, max_iter=100,multi_class= 'ovr',fit_intercept=False,C=10,\\\n",
    "                        dual=True,solver='liblinear')\n",
    "\n",
    "results_skfold = model_selection.cross_val_score(model1, train_features,y_train, cv=skfold,n_jobs=-1)\n",
    "print(\"Accuracy: %.2f%%\" % (results_skfold.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=LogisticRegression(random_state=100,n_jobs=-1, max_iter=100,multi_class= 'ovr',fit_intercept=False,C=10,\\\n",
    "                        dual=True,solver='liblinear')\n",
    "model1.fit(train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_output = os.path.join(\"../models/\", \"logistic_regression_model.pkl\")\n",
    "print('Saving trained logistic_regression model  to {}'.format(model_output)) \n",
    "f=open(model_output, \"wb\")\n",
    "pickle.dump( model1,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
